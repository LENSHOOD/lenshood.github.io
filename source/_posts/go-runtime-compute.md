---
title: Go Runtime 设计：计算资源调度
mathjax: true
date: 2022-03-10 00:34:44
tags: 
- source
- go
categories:
- Golang
---

## 1. 为什么需要 GoRoutine？

### 1.1 多少个线程是最优的？

我们知道，计算机执行一项任务，通常情况下需要由计算、存储、I/O 等多个组件配合运转才能完成。由于 CPU 与其他设备之间速度的巨大差异，我们更倾向于利用多任务同时运行的方式，来最大化的利用 CPU 的计算能力，这也就是并发编程的意义所在。

而由于多核处理器的广泛普及，在多个 CPU 核心上 ”并行的“ 进行多任务 ”并发“，是编写高效程序的必经之路。从程序执行层次的角度看，”并行“ 更倾向于在底层语境下，指代多个 CPU 核心能同时执行代码片段，而 ”并发“ 更倾向于在高层语境下，指代多个任务能同时在计算机上运行。

OS 通过调度机制帮我们实现了将用户层面的多任务并发，映射到硬件层面的多核心并行。从最大化资源利用的角度讲（暂时抛开任务执行公平性不谈），其映射机制，是对 CPU 资源的一种 “超卖”：任务可能处于执行和等待（包括阻塞）两种状态，执行状态下需要 CPU 资源而等待状态下则可以出让 CPU 资源给其他任务使用。根据任务类型的不同，通常可能分成 CPU 密集型任务与 I/O 密集型任务。

那么理论上，到底要同时执行多少个任务（线程数），才能最大化的利用计算资源呢？《Java 并发编程实战》中给出了如下公式：
$$
N_{threads}=N_{cpu}*U_{cpu}*(1+\frac{W}{C})
\\
\\
N_{threads}=number\ of\ CPUs
\\
U_{cpu}=target\ CPU\ utilization,\ 0\leqslant U_{cpu} \leqslant 1
\\
\frac{W}{C}=ratio\ of\ wait\ time\ to\ compute\ time
$$
显然，基于资源最大化考虑，我们期望 $U_{cpu} \to 1$。

那么，对于计算密集型任务，随着计算占比的不断提高，其 $\frac{W}{C} \to 0$，因此 $N_{threads} \to N_{cpu}$ ；而对于 I/O 密集型任务，随着 I/O 等待占比的不断提高，其 $\frac{W}{C} \to \infin$ ，因此 $N_{threads} \to \infin$。



### 1.2 线程越多越好吗？

前面我们看到了，对于 I/O 占比较高的 I/O 密集型任务，理论公式中倾向于创建更多的线程来填补 CPU 的空闲，但这并不是零成本的。

关于线程所带来的开销，Eli Bendersky 在他的博文 [Measuring context switching and memory overheads for Linux threads](https://eli.thegreenplace.net/2018/measuring-context-switching-and-memory-overheads-for-linux-threads/) 中做了一些测量，

1. 上下文切换与启动的开销：

   ![](https://eli.thegreenplace.net/images/2018/plot-launch-switch.png)

​		可以看到在线程绑核切换下，上下文切换的开销每次大约 2us，线程启动开销大约 5us。

2. 内存开销：

   线程的内存开销主要体现在线程栈，他的[代码示例](https://github.com/eliben/code-for-blog/blob/master/2018/threadoverhead/threadspammer.c)表明，10000 个各持有 100KiB 实际栈空间消耗的线程，virtual memory 约为 80GiB（未实际分配），RSS 约为 80MiB。

Eli Bendersky 的文章主要想表达的是现代操作系统的线程开销已经非常小了，很多时候我们并不需要采用事件驱动等方式来增加复杂度，目前的操作系统支持数万个线程绰绰有余。

但假如我们想要数十万、上百万的线程呢？假如在不增加复杂度的前提下，能做到更低的开销呢？golang 用 goroutine 给出了解决方案。

在 Eli Bendersky 的文章中，测试线程切换的用例是让两个线程通过一个管道往复传递数据，结果是在一秒内，大概能来回传递 40 万次。而后他又顺手用 go 重写了[测试代码](https://github.com/eliben/code-for-blog/blob/master/2018/threadoverhead/channel-msgpersec.go)，得到的结果是：每秒 280 万次。

不论如何，无节制的创建新线程，最终一定会产生许多安全性问题，如过多的上下文切换，内存耗尽等等。



### 1.3 限制最大线程数

既然我们不能容忍无限制创建线程，那么最直接想到的自然是设定一个线程数上限，当线程超限后，拒绝再创建新的线程。

线程池是最通用的解决方案。

// 图 thread pool

池化是资源复用的常见方式，线程池可以最多持有 n 个工作线程（当然根据工作负载的变化，n 可以是动态的），同时持有一个任务队列。工作线程执行如下的循环：从队列获取任务 -> 执行任务 -> 再次从队列获取任务，因此如果没有空闲的工作线程，任务就必须在队列等待。

线程池不仅能限制线程的最大数量，同时也能降低线程反复创建、销毁产生的开销。对于突发的大规模任务也能比较优雅的实现降级、削峰填谷等措施。



### 1.4 换种思路

对于 I/O 密集型的任务，执行过程中有很大一部时间都在等待，当 I/O 返回时任务才能继续工作。也正是这种等待的特点，给了我们创建多线程来提高 CPU 利用率的理由：阻塞等待中的线程不需要 CPU 时间。

设想假如我们将这种机制反过来，线程不是阻塞等待被唤醒，而是主动询问所有正在等待的 I/O，检查某个 I/O 是不是返回了。如果返回了，就处理与之关联的任务，而如果没有返回，线程就继续检查下一个等待中的 I/O，或者创建新的 I/O 调用。

与阻塞唤醒的被动式相比，询问的方式会更加主动。原先的 “执行任务 -> I/O 阻塞 -> 继续执行” 的流程，变成了 “执行任务 -> 注册 I/O 事件 -> 回调任务“。

这种模式称之为事件驱动的并发编程模型，线程进行轮询（poll）的动作，称为事件循环。

// 图 event loop

从工作原理上我们就能发觉，事件驱动模型有如下的特点：

- 不需要很多线程：与多线程通过阻塞出让 CPU 相比，主动切换任务继续使用 CPU 资源，实际上是绕过了系统调度器
- 需要通过回调函数来保持事件与任务的关联关系：通过事件回调来继续执行先前被中断的任务
- 主线程不允许存在阻塞：
  - 在多线程模型下对资源的阻塞等待式访问，需要全部替换成非阻塞式访问，否则一旦出现阻塞，将导致事件轮询线程无法继续轮询。
  - 对于阻塞 I/O 实际上还是需要引入线程池，但此时的 I/O 线程只负责 I/O 操作，不再负责处理任务逻辑




### 1.5 Callback Hell

在事件驱动模型里，将耗费时间的 I/O 阻塞调用交给线程池进行异步化，在阻塞调用返回后，通过调用 callback 函数来恢复执行任务逻辑。

这种方式在简单的任务逻辑中运行的很好，然而当存在一个任务，其整个逻辑链条中包含了多个相互依赖的阻塞 I/O，这时 callback 函数的注册链路会不断加深，最后形成难以理解的 ”Callback Hell“。

// 图 callback hell

产生 Callback Hell 的本质是什么？需要通过参数传递上下文。

注册回调函数时，将回调函数地址作为参数传递给事件注册器，是为了能够在合适的时机被调用。回调函数内访问的外部变量，是由编译器默默地通过闭包传递（不支持闭包的语言需要在堆上分配对象，并通过参数传递其地址）。

因为没有外部协助，所以我们需要在应用代码中通过回调函数进行上下文传递，随着传递次数的增多，就导致了回调地狱。

那么，假设：

1. 如果能通过一些手段更优雅的维护任务的上下文，就不需要在参数中层层嵌套传递上下文
2. 如果不需要嵌套回调函数，就能像写同步阻塞的多线程代码一样写事件驱动的异步代码，进而方便的实现任务间的交互协作

基于上述讨论，我们自然会发现，通过将应用逻辑拆分成一个个小的异步任务（而不是同步函数调用），并且通过合理的方式维护任务上下文，我们能够实现任务间的切换和调度。

这已经覆盖了系统调度器的绝大部分工作内容（除了抢占，事件循环类似于协作式调度），任务可以类比为线程，不同点在于任务之间切换是协作式的（等待资源时主动出让 CPU），假如一个任务不主动出让线程，他就能永久的拥有该线程。对于这种执行协作式任务的模型，我们可以称之为协程（co-routine）模型。

> 这里需要注意的是，协程模型的提出相比线程模型更早。线程通过抢占式调度解决了协程的协作式调度对资源使用的的非公平性。

对于维护上下文的问题，协程模型的解决方式有两种：

- 有栈式：通过保存、恢复现场，将协程的调用栈保存在协程结构内部
- 无栈式：将协程之间的上下文保存在外部，常见的办法是有限状态机



### 1.6 用户级调度器





## 2. 集中式调度器抽象存在什么问题？

## 3. 什么是 G-P-M 模型？

## 4. 如何实现调度？

## 5. 如何实现抢占？

