---
title: 性能工程实践
date: 2023-07-13 21:28:12
tags:
- performance engineering
- performance optimization
- performance analysis
categories:
- Software Engineering
---

本文书接上篇《什么是性能工程》，通过介绍相关实践、方法与尝试，试图回答企业如何达成性能工程目标的问题。



## 前言

经过上一篇内容《什么是性能工程》的讨论，我们引出了 *“性能工程，是指通过设计、构建工具链和工作流，从而对系统性能进行持续改善和守护的一类实践方法”* 这一观点，并基于此定义了落地性能工程的目标：

**DevPerfOps：构建性能工程反馈闭环**

**固化专家经验形成知识库，沉淀性能优化标准实践**

**自助化性能分析，降低工具学习和使用成本**

本文将围绕着上述三个建设目标，通过介绍相关的尝试和方法，以讨论企业建设性能工程体系的最佳实践。

后文将介绍如下几个方法实践：

1. 以技术支撑研发流程再造的过程，实现性能左移。
2. 守护性能基线，及时发现性能劣化，并通过定界技术缩小劣化范围。
3. 构建性能工程平台，沉淀工具、知识和模式，打造一站式性能优化能力。



## 性能左移：技术支撑的流程再造

上篇文章提到过，现有的成熟研发流程中，性能往往被忽视，导致与性能相关的工作不断被后置。

性能左移恰恰是尝试将性能相关的工作尽量前置，向研发流程的左侧移动。这包括设计阶段的性能建模，开发阶段的性能实践以及测试阶段的性能测试。

早期落地 DevOps 的经验告诉我们，由于人的因素，仅通过改变工作流程和内容，而不提供相应的技术支撑，是难以实现流程的再造和更新的。

性能左移也不例外，为了实现性能左移的目标，我们扩展了自动化流水线，并提供了相应技术实践，扩展后的流水线图如下所示：

图

解释

**性能建模与架构评议**

性能建模是整个流程的第一个环节。其内容一方面包含了在设计阶段需要明确的系统性能要求，例如功能响应时间、关键路径的吞吐量、服务的并发量等，以及对资源利用率相关的要求和设计，如弹性扩缩指标，系统容量规划和预估等。

另一方面则包含了架构的性能关注点地图。关键的业务模块、性能阻塞概率大的组件以及各种交互接口都属于性能关注点的范畴。性能关注点地图能够在性能分析和优化时为我们提供逻辑、交互、算法和数据结构上的设计信息，并引导我们聚焦在关键路径和更易发生性能劣化的地方。

性能建模将与其他设计产出物一同进入架构评议环节进行评审。为了确保在后续流程中设计约束不被破坏，相关设计约束将以门限的形式挂载到流水线上，以守护约束不被破坏。各种门限包括对比指标达成，关键点测试覆盖率等。

**代码扫描与微基准测试**

在开发阶段，面对业务功能上的开发要求，开发者可能无暇顾及具体的性能设计。通过代码扫描工具，能够低成本的找出性能不友好的代码段，并提示开发者及时修改。目前市面上有众多静态扫描工具可供选择，它们不仅能识别性能问题，也能发现安全和质量问题。

如果开发的功能被识别为性能关注点，则需要开发者为关键代码编写微基准测试。可以通过插桩、埋点等形式将性能关注点地图与分析系统关联起来，每一次进行流水线构建都会执行开发者编写的微基准测试，其测试结果会通过插桩点上报给分析系统，以供统计和分析。

**测试框架与插件市场**

传统流程中，性能测试占比本身较低，因此通过简单的脚本式用例结合常见的性能探测工具就可以满足性能测试的需求。但随着性能左移的落地，测试环节对性能测试的要求从孤立功能的通用指标测试转化为对系统整体的性能仿真以及多维度的指标验证，此时传统性能测试方法将因效率低下而难以为继。

通过逐步构建并形成符合企业自身场景的性能测试体系，能够为性能测试提供基础能力支撑。成熟的测试框架，一方面集成了标准化的用例模板或脚手架，简化通用场景用例的编写，另一方面可为用例编写者提供负载生成、指标收集、执行编排、分析可视化等各类原子工具，方便按需组合。

最后，建立插件市场，将上述用例模板和原子化工具在企业内部开放并自下而上形成生态闭环。



## 持续改进：性能看护+定界分析

DevPerfOps 要求能实现性能工程的反馈闭环。性能左移已经让性能工作尽可能前置，但为了实现完整的反馈闭环，性能测试之后的阶段才是关键。

系统上线后，真实的运行数据将不断验证性能指标是否满足要求，对发现的性能问题，也会开展性能优化工作。但系统并非一成不变，随着不断的版本迭代，各类性能问题可能也会反复发生。为了能持续的监控系统性能，更快地发现性能变化并定位导致变化的代码块，需要支持性能看护和定界分析的能力。

**动态看护，统计性能变化**

看护的本质是建立基线，度量变化。上线前性能测试和上线后性能监控都可以产生大量性能指标数据，对指标数据进行清洗和筛选后，能够形成不同环境下的性能基线。在版本迭代过程中，通过对比基线，能方便的发现性能变化点和劣化点。

传统的性能基线大都来自于施加外部负载而得到的整体性监控数据，这种将系统看做黑盒的基线缺少细节性能数据，导致即使通过基线对比发现了指标劣化，也难以准确发现问题。而我们基于性能关注点地图，可以设置更细致的监控追踪点，对系统形成了更深入的洞察。因此能够实现将黑盒观测数据与进程级、组件级观测数据相结合，使看护报告能提供进一步信息检视诊断的能力，从而帮助定位性能劣化根因。

理想情况下，性能指标数据的变化服从高斯分布，因此很容易统计和对比。然而实际场景下，性能指标的波动趋势远比仿真环境下复杂得多，通过概率统计方法对指标数据进行处理后，才能形成判断性能劣化的依据。常见的，指标分布中出现少量离群点，可能预示着出现了环境问题或是功能故障，而指标分布偏左或偏右表示可能存在未分离的变量影响，需要增加观测指标。

**定界分析，缩小责任边界**

看护报告可以指出哪几个关联指标出现劣化，顺着这些指标我们大致能将性能劣化范围缩小到到服务或模块级别。但这种级别的指标数据粒度还是太粗，为了实施性能优化，需要的是更细粒度的性能数据分析，才能找到具体的劣化代码块。

为了深入的了解服务或模块的性能变化，一般采用性能剖析的手段，在函数级别进行数据采样。函数级别下的性能剖析，能够生成函数调用栈、函数总耗时 / On CPU 耗时、函数内存消耗、堆内存分析等报告。大多数情况下，通过性能剖析就能发现劣化代码块。进一步的，对劣化代码进行优化后，再次做剖析，前后差分对比可以分析优化效果。

成功的优化不仅能改善系统性能，还可以与相关的多个性能指标进行关联。收集优化前后各类指标数据的变化，积累起来形成指标特征，可以训练生成性能劣化模型。在未来的性能看护场景下，发现指标劣化后，系统能自动尝试进行根因分析，给出可能的劣化点位置以及匹配到的优化案例，从而进一步降低性能优化的成本。



## 一站式优化：构建性能工程平台能力

1. 启发式分析流
2. 模式+分析图谱+专家协助



## 性能工程的成熟度路线

1. 流程化
2. 数字化
3. 知识化
4. 资产化
5. 常态化



## 总结

